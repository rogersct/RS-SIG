{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_equal(a,b):\n",
    "    try:\n",
    "        np.testing.assert_equal(a,b)\n",
    "    except AssertionError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \"\"\"Return a dataframe\n",
    "    \n",
    "    Clean up the dataframe for any duplicates or null values\n",
    "    \"\"\"\n",
    "    count_start = len(df)\n",
    "    \n",
    "    # Does it make sense to drop duplicates?\n",
    "#     # Clean - Drop duplicates entries\n",
    "#     df.drop_duplicates(keep=False,inplace=True)\n",
    "#     # Clean - Check for duplicates counts\n",
    "#     print(\"Number of duplicates dropped = \",  count_start-len(df))\n",
    "\n",
    "    # Clean - Drop null value entries\n",
    "    count_start = len(df)\n",
    "    df = df.dropna(how='any',axis=0)\n",
    "    # Clean - Check for null value counts\n",
    "    print(\"Number of null value entry = \",  count_start-len(df))\n",
    "    return df\n",
    "\n",
    "def check_for_monotonic (df):\n",
    "    \"\"\" Return a dataframe\n",
    "    \n",
    "    Detect and clean unsequence real time\n",
    "\n",
    "    \"\"\"\n",
    "    if not df['Realtime'].is_monotonic_increasing:\n",
    "        # Get index of non-monotonic location - non increasing order\n",
    "        df_non_monotonic = df.loc[df['Realtime'].diff() < pd.to_timedelta('0 seconds')]\n",
    "        \n",
    "        # *** Need to determine if for loop forward or backwards (changing to which real time index) - Not Implemented\n",
    "        \n",
    "        print(\"Found non-monotonic sequence at index: \", (df.loc[df['Realtime'].diff() < pd.to_timedelta('0 seconds')].index))\n",
    "        for index in df_non_monotonic.index:\n",
    "            non_monotonic_realtime = df['Realtime'][index-1]\n",
    "            count_non_monotonic_realtime = len(df[df['Realtime'] == non_monotonic_realtime].index)\n",
    "                       \n",
    "            # Find start location of index with the same real time (index)\n",
    "            start_index = min(df[df['Realtime'] == df['Realtime'][index]].index)\n",
    "            count_first_realtime = len(df[df['Realtime'] == df['Realtime'][index]].index)\n",
    "            \n",
    "            total_count = count_first_realtime + count_non_monotonic_realtime\n",
    "            windows = total_count // 2\n",
    "            first_realtime_windows = total_count - windows\n",
    "            \n",
    "            # Next time index information\n",
    "            start_index_next_realtime = start_index + first_realtime_windows\n",
    "                               \n",
    "            # Update First Real Time\n",
    "            for count in range (0,first_realtime_windows):\n",
    "                df.loc[start_index+count,'Realtime'] = df['Realtime'][index]\n",
    "                print(start_index+count, df.loc[start_index+count,'Realtime'])\n",
    "                                \n",
    "            # Update Real time for the next time index\n",
    "            for count in range (0,windows):\n",
    "                df.loc[start_index_next_realtime+count,'Realtime'] = non_monotonic_realtime\n",
    "                print(start_index_next_realtime+count, df.loc[start_index_next_realtime+count,'Realtime'])\n",
    "    return df\n",
    "\n",
    "def preprocess_machine_time(df):\n",
    "    \"\"\"Return a dataframe\n",
    "    \n",
    "    Convert Machine Time (Column 'Date') to Unix Timestamp with Millisecond Resolution\n",
    "    \"\"\"\n",
    "    # Date to Unix Timestamp\n",
    "    #df.info(verbose=True)\n",
    "    # Convert Date object (mm/dd/yyyy hh:mm:ss)to datetime type\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    # Convert datetime to timestamp (Unix) in milisecond resolution\n",
    "    df['Timestamp'] = df.Date.values.astype(np.int64) // 10 ** 9 *1000\n",
    "\n",
    "    #df['Converted Date'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "    #df.head(20)\n",
    "    #df.info(verbose=True)\n",
    "\n",
    "    # Add column for Timestampms\n",
    "    df['Timestampms'] = \"\"\n",
    "    df['Timestampms'].replace('','0',inplace=True)\n",
    "    df[\"Timestampms\"] = df[\"Timestampms\"].astype(np.int64)\n",
    "    \n",
    "#     # Add column for interval_ms\n",
    "#     df['interval_ms'] = \"\"\n",
    "#     df['interval_ms'].replace('','0',inplace=True)\n",
    "#     df[\"interval_ms\"] = df[\"interval_ms\"].astype(np.int64)\n",
    "#     #df.info(verbose=True)\n",
    "\n",
    "    # # Create empty dataframe\n",
    "    # df2 = pd.DataFrame(data=None, columns=df.columns)\n",
    "\n",
    "    # list_df = []\n",
    "    # list_df.append(df2)\n",
    "    #Iterate through unique Timestamp - Add milisecond to Machine Time\n",
    "    for item in sorted(df[\"Timestamp\"].unique()):\n",
    "        #timestamp_df = df.query('Timestamp==@item')\n",
    "        timestamp_df = df.loc[df['Timestamp'] == item]\n",
    "        # For every Timestamp (1000 millisecond), find the interval\n",
    "        interval_ms = round(1000 / timestamp_df.shape[0])\n",
    "        counter = 0\n",
    "        for index, row in timestamp_df.iterrows():\n",
    "            #print(index)\n",
    "            df.loc[index,'Timestampms'] = row.Timestamp + counter*interval_ms\n",
    "            #df.loc[index,'interval_ms'] = interval_ms\n",
    "            counter += 1\n",
    "    \n",
    "    #list_df.append(timestamp_df)\n",
    "    return df\n",
    "\n",
    "            \n",
    "def generate_real_time(x):\n",
    "    \"\"\"Return real time\n",
    "    \n",
    "    Check if real time needs to increase by 1 day\n",
    "    \"\"\"\n",
    "    time_difference = datetime.timedelta(hours = x.Hour, minutes = x.Minute, seconds = x.Second) - datetime.timedelta(hours = real_time_start.hour, minutes = real_time_start.minute, seconds = real_time_start.second)\n",
    "    datetime_real_time = datetime.datetime.combine(x.Date.date(), datetime.time(x.Hour, x.Minute, x.Second))\n",
    "                                                  \n",
    "    if(time_difference < datetime.timedelta(days=0)):\n",
    "        print(\"Increase by 1 day\")\n",
    "        datetime_real_time = datetime_real_time + datetime.timedelta(days=1)\n",
    "\n",
    "    x['Realtime'] = datetime_real_time\n",
    "    return x['Realtime']\n",
    "                                                   \n",
    "    \n",
    "def preprocess_real_time(df):\n",
    "    \"\"\"Return a dataframe\n",
    "    \n",
    "    Convert Real Time (Columns 'Hour', 'Minute', Second) to datetime.time with Millisecond Resolution\n",
    "    \"\"\"\n",
    "    # Combine Hours Minutes and Seconds to datetime\n",
    "    #df['Millisecond'] = \"\"\n",
    "    df['Realtime'] = \"\"\n",
    "    df['Realtime'].replace('','0',inplace=True)\n",
    "    df[\"Realtime\"] = df[\"Realtime\"].astype(np.int64)\n",
    "    global real_time_start \n",
    "    real_time_start = datetime.time(df.Hour[0], df.Minute[0], df.Second[0])\n",
    "    df['Realtime'] = df.apply(generate_real_time, axis=1)                                               \n",
    "#     df['Realtime'] = df.apply(lambda row: \n",
    "#                               datetime.datetime.combine(row.Date.date(), datetime.time(row.Hour, row.Minute, row.Second)), \n",
    "#                               axis=1)\n",
    "    # Check for unsequence Real Time (Non-Monotonic)\n",
    "    df = check_for_monotonic(df)\n",
    "    \n",
    "    # Convert Date object (mm/dd/yyyy hh:mm:ss)to datetime type\n",
    "    df['Realtime'] = pd.to_datetime(df['Realtime'], format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "    # Convert datetime to timestamp (Unix) in milisecond resolution\n",
    "    df['Real_Timestamp'] = df.Realtime.values.astype(np.int64) // 10 ** 9 *1000\n",
    "    \n",
    "    #df.info(verbose=True)\n",
    "    \n",
    "    # Add column for Real_Time Timestampms\n",
    "    df['Real_Timestampms'] = \"\"\n",
    "    df['Real_Timestampms'].replace('','0',inplace=True)\n",
    "    df[\"Real_Timestampms\"] = df[\"Real_Timestampms\"].astype(np.int64)\n",
    "\n",
    "    #Iterate through unique Real_Timestamp - Add milisecond to Real Time\n",
    "    for item in sorted(df[\"Real_Timestamp\"].unique()):\n",
    "        #timestamp_df = df.query('Timestamp==@item')\n",
    "        real_timestamp_df = df.loc[df['Real_Timestamp'] == item]\n",
    "        # For every Timestamp (1000 millisecond), find the interval\n",
    "        interval_ms = round(1000 / real_timestamp_df.shape[0])\n",
    "        counter = 0\n",
    "        for index, row in real_timestamp_df.iterrows():\n",
    "            #print(index)\n",
    "            df.loc[index,'Real_Timestampms'] = row.Real_Timestamp + counter*interval_ms\n",
    "            counter += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(lst, K):\n",
    "    \"\"\"Return a index for the closest value\n",
    "    \n",
    "    Find the closest value inside the list\n",
    "    \"\"\"\n",
    "    return min(range(len(lst)), key = lambda i: abs(lst[i]-K)) \n",
    "\n",
    "def calculate_ATO_real_timestampms(x):\n",
    "    \"\"\"Return ATO Real Time and nearest index\n",
    "    \n",
    "    With the unmapped ATP machine time, we need to calculate it's equivalent ATO Real Time by\n",
    "    finding the closest ATO machine time\n",
    "    \"\"\"\n",
    "    if(pd.isnull(x['Real_Timestampms'])):\n",
    "        if x.name == 0:\n",
    "            # The closest is the next index\n",
    "            x['nearest_index'] = 1\n",
    "            x['Real_Timestampms'] = abs(df_result.loc[x.name+1,'Timestampms'] - df_result.loc[x.name,'Timestampms']) + df_result.loc[x.name+1,'Real_Timestampms']\n",
    "            \n",
    "        else:\n",
    "            # Find the closest between the index before and after\n",
    "            difference_before = df_result.loc[x.name-1,'Timestampms']\n",
    "            difference_after = df_result.loc[x.name+1,'Timestampms']\n",
    "            index_timestampms = df_result.loc[x.name,'Timestampms']\n",
    "            difference_list = [difference_before, difference_after]\n",
    "            # Find nearest index\n",
    "            nearest_index = nearest(difference_list, index_timestampms)\n",
    "            x['nearest_index'] = nearest_index\n",
    "            if nearest_index == 0:\n",
    "                # Compute ATO Real Time - if nearest_index is the index before, take difference between the two Machine time\n",
    "                # and add it to the equivalent ATO real time to preseve the ATP's time interval\n",
    "                x['Real_Timestampms'] = abs(index_timestampms - difference_before) + df_result.loc[x.name-1,'Real_Timestampms']\n",
    "            else:\n",
    "                # Compute ATO Real Time - if nearest_index is the index after, take difference between the two Machine time\n",
    "                # and add it to the equivalent ATO real time to preseve the ATP's time interval\n",
    "                x['Real_Timestampms'] = abs(difference_after - index_timestampms) + df_result.loc[x.name+1,'Real_Timestampms']\n",
    "            \n",
    "    \n",
    "    return pd.Series([x['Real_Timestampms'], x['nearest_index']])\n",
    "\n",
    "def indicate_switch(x):\n",
    "    \"\"\"Return nearest index\n",
    "    \n",
    "    With previous row's nearest_index indicating 1 (needs to be switched after the index after),\n",
    "    set the current row's nearest_index as 2\n",
    "    \"\"\"\n",
    "    if(x.name>0):\n",
    "        if df_result.loc[x.name-1,'nearest_index'] == 1:\n",
    "            x['nearest_index'] = 2\n",
    "    \n",
    "    return x['nearest_index']\n",
    "\n",
    "def switch_row_position(x):\n",
    "    \"\"\"Return dataframe\n",
    "    \n",
    "    Retrieve row based on nearest_index to perform switching of row when required\n",
    "    \"\"\"\n",
    "    if(x['nearest_index']==1):\n",
    "        #if nearest_index is the index after, switch\n",
    "        return df_result.iloc[x.name+1]\n",
    "    elif(x['nearest_index']==2):\n",
    "        return df_result.iloc[x.name-1]\n",
    "    else:\n",
    "        #if nearest_index is the index before, remain the order\n",
    "        return df_result.iloc[x.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "index_file = 0\n",
    "sample_output_filename = './OMAP_Train_20_Car_39_20200116_0600_to_20200116_0700.csv'\n",
    "#sample_output_filename = './OMAP_Train_20_Car_39_20200116_0700_to_20200116_0800.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200116_05_00_00_333_OMAP_ATO.txt', '200116_06_00_00_333_OMAP_ATO.txt', '200116_07_00_00_333_OMAP_ATO.txt']\n",
      "Number of null value entry =  0\n",
      "Found non-monotonic sequence at index:  Int64Index([26005, 34767], dtype='int64')\n",
      "25991 2020-01-16 06:29:07\n",
      "25992 2020-01-16 06:29:07\n",
      "25993 2020-01-16 06:29:07\n",
      "25994 2020-01-16 06:29:07\n",
      "25995 2020-01-16 06:29:07\n",
      "25996 2020-01-16 06:29:07\n",
      "25997 2020-01-16 06:29:07\n",
      "25998 2020-01-16 06:29:07\n",
      "25999 2020-01-16 06:29:07\n",
      "26000 2020-01-16 06:29:07\n",
      "26001 2020-01-16 06:29:07\n",
      "26002 2020-01-16 06:29:07\n",
      "26003 2020-01-16 06:29:07\n",
      "26004 2020-01-16 06:29:07\n",
      "26005 2020-01-16 06:29:07\n",
      "26006 2020-01-16 06:29:07\n",
      "26007 2020-01-16 06:29:07\n",
      "26008 2020-01-16 06:29:08\n",
      "26009 2020-01-16 06:29:08\n",
      "26010 2020-01-16 06:29:08\n",
      "26011 2020-01-16 06:29:08\n",
      "26012 2020-01-16 06:29:08\n",
      "26013 2020-01-16 06:29:08\n",
      "26014 2020-01-16 06:29:08\n",
      "26015 2020-01-16 06:29:08\n",
      "26016 2020-01-16 06:29:08\n",
      "26017 2020-01-16 06:29:08\n",
      "26018 2020-01-16 06:29:08\n",
      "26019 2020-01-16 06:29:08\n",
      "26020 2020-01-16 06:29:08\n",
      "26021 2020-01-16 06:29:08\n",
      "26022 2020-01-16 06:29:08\n",
      "26023 2020-01-16 06:29:08\n",
      "26024 2020-01-16 06:29:08\n",
      "34751 2020-01-16 06:44:02\n",
      "34752 2020-01-16 06:44:02\n",
      "34753 2020-01-16 06:44:02\n",
      "34754 2020-01-16 06:44:02\n",
      "34755 2020-01-16 06:44:02\n",
      "34756 2020-01-16 06:44:02\n",
      "34757 2020-01-16 06:44:02\n",
      "34758 2020-01-16 06:44:02\n",
      "34759 2020-01-16 06:44:02\n",
      "34760 2020-01-16 06:44:02\n",
      "34761 2020-01-16 06:44:02\n",
      "34762 2020-01-16 06:44:02\n",
      "34763 2020-01-16 06:44:02\n",
      "34764 2020-01-16 06:44:02\n",
      "34765 2020-01-16 06:44:02\n",
      "34766 2020-01-16 06:44:02\n",
      "34767 2020-01-16 06:44:02\n",
      "34768 2020-01-16 06:44:02\n",
      "34769 2020-01-16 06:44:03\n",
      "34770 2020-01-16 06:44:03\n",
      "34771 2020-01-16 06:44:03\n",
      "34772 2020-01-16 06:44:03\n",
      "34773 2020-01-16 06:44:03\n",
      "34774 2020-01-16 06:44:03\n",
      "34775 2020-01-16 06:44:03\n",
      "34776 2020-01-16 06:44:03\n",
      "34777 2020-01-16 06:44:03\n",
      "34778 2020-01-16 06:44:03\n",
      "34779 2020-01-16 06:44:03\n",
      "34780 2020-01-16 06:44:03\n",
      "34781 2020-01-16 06:44:03\n",
      "34782 2020-01-16 06:44:03\n",
      "34783 2020-01-16 06:44:03\n",
      "34784 2020-01-16 06:44:03\n",
      "34785 2020-01-16 06:44:03\n",
      "34786 2020-01-16 06:44:03\n",
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Read files from ATO Directory\n",
    "path = './T20 OMAP DATA/Train 20 CSV/Car 39/200116/OMAP_ATO/'\n",
    "ATO_file_list = os.listdir(path)\n",
    "sorted(ATO_file_list)\n",
    "print(ATO_file_list)\n",
    "# Read & Clean the first ATO .txt\n",
    "df = pd.read_csv(path + ATO_file_list[index_file], sep=\"\\t\")\n",
    "df = clean_dataframe(df)\n",
    "\n",
    "# Preprocess Machine Time\n",
    "df = preprocess_machine_time(df)\n",
    "#df2 = pd.concat(list_df) # Concat a list of dataframes is faster than appending individual dataframes\n",
    "# Preprocess Real Time\n",
    "df = preprocess_real_time(df)\n",
    "\n",
    "print(df.loc[df['Realtime'].diff() < pd.to_timedelta('0 seconds')].index)\n",
    "#df.to_csv('./clean_real_time.csv', index=False, header=True)\n",
    "# Drop Date, Timestamp & Real Time Timestamp Columns\n",
    "df.drop(['Date', 'Timestamp', 'Realtime','Real_Timestamp'], inplace=True, axis=1)\n",
    "    \n",
    "# Add Prefix to Columns name (ATO_***)\n",
    "df = df.add_prefix('ATO_')\n",
    "# Rename ATO_Timestampms to the column Timestampms \n",
    "df.rename(columns = {\"ATO_Timestampms\": \"Timestampms\"},  inplace = True)\n",
    "df.rename(columns = {\"ATO_Real_Timestampms\": \"Real_Timestampms\"},  inplace = True) \n",
    "# Shift Timestampms to first column\n",
    "df = df[ ['Real_Timestampms'] + [ col for col in df.columns if col != 'Real_Timestampms' ] ]\n",
    "df = df[ ['Timestampms'] + [ col for col in df.columns if col != 'Timestampms' ] ]\n",
    "#df.head(20)\n",
    "# Note that there are 280 columns belonging to ATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200116_05_00_00_333_OMAP_TDMS.txt', '200116_06_00_00_333_OMAP_TDMS.txt', '200116_07_00_00_333_OMAP_TDMS.txt']\n",
      "Number of null value entry =  0\n"
     ]
    }
   ],
   "source": [
    "# Read files from TDMS Directory\n",
    "path = './T20 OMAP DATA/Train 20 CSV/Car 39/200116/OMAP_TDMS/'\n",
    "TDMS_file_list = os.listdir(path)\n",
    "sorted(TDMS_file_list)\n",
    "print(TDMS_file_list)\n",
    "\n",
    "# Read & Clean the first ATP .txt\n",
    "df_TDMS = pd.read_csv(path + TDMS_file_list[index_file], sep=\"\\t\")\n",
    "df_TDMS = clean_dataframe(df_TDMS)\n",
    "\n",
    "# Preprocess Machine Time\n",
    "df_TDMS = preprocess_machine_time(df_TDMS)\n",
    "\n",
    "# Add Prefix to Columns name (TDMS_***)\n",
    "df_TDMS = df_TDMS.add_prefix('TDMS_')\n",
    "# Rename ATP_Timestampms to the column Timestampms \n",
    "df_TDMS.rename(columns = {\"TDMS_Timestampms\": \"Timestampms\"},  inplace = True) \n",
    "\n",
    "#df_TDMS.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 44292/44292 [00:09<00:00, 4636.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 44292/44292 [00:01<00:00, 28460.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 44292/44292 [00:26<00:00, 1690.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 40.2465418\n"
     ]
    }
   ],
   "source": [
    "# Merge TDMS Dataframe to result Dataframe with same Timestampms\n",
    "df_result = pd.merge_ordered(df, df_TDMS, how='outer', on='Timestampms')\n",
    "#Output to CSV\n",
    "#df_result.to_csv('./result_4.csv', index=False, header=True)\n",
    "\n",
    "# Nearest_index to indicate switch condition 0: Remain, 1:Take index after, 2: Take index before\n",
    "df_result['nearest_index'] = \"\"\n",
    "\n",
    "# Compute ATP real time and map it onto ATO while maintaining the ATP's time interval\n",
    "df_result[['Real_Timestampms', 'nearest_index']] = df_result.progress_apply(calculate_ATO_real_timestampms, axis=1)\n",
    "# Indicate which row needs to be switched\n",
    "df_result['nearest_index'] = df_result.progress_apply(indicate_switch, axis=1)\n",
    "# Switch row position \n",
    "df_result = df_result.progress_apply(switch_row_position, axis=1)\n",
    "# Sort Real Time\n",
    "#df_result['Timestampms'] = df_result['Timestampms'].sort_values().values\n",
    "df_result = df_result.sort_values(by='Real_Timestampms',ascending=True).reset_index(drop=True)\n",
    "df_result = df_result.drop(['Timestampms', 'TDMS_Date', 'TDMS_Timestamp', 'nearest_index'], axis=1)\n",
    "df_result_ATO_TDMS = df_result.copy(deep=True)\n",
    "del df_result\n",
    "\n",
    "#Output to CSV\n",
    "#df_result_ATO_TDMS.to_csv('./result_5.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44292, 438)\n",
      "None\n",
      "None\n",
      "             ATO_1220_Energy_delta  ATO_2008_ATP_Energy_delta\n",
      "29000 self                 223.434                    223.434\n",
      "      other                223.434                    223.434\n",
      "29001 self                 223.434                    223.434\n",
      "      other                223.434                    223.434\n",
      "29002 self                 223.434                    223.434\n",
      "...                            ...                        ...\n",
      "44282 other                677.366                    677.366\n",
      "44283 self                 677.366                    677.366\n",
      "      other                677.366                    677.366\n",
      "44284 self                 677.366                    677.366\n",
      "      other                677.366                    677.366\n",
      "\n",
      "[1550 rows x 2 columns]\n",
      "Equality Between Sample Output and Self Processed:  True\n"
     ]
    }
   ],
   "source": [
    "# Unit Test for ATO to TDMS\n",
    "# Import Output File\n",
    "df_output = pd.read_csv(sample_output_filename)\n",
    "#df_output = pd.read_csv('./OMAP_Train_20_Car_39_20200116_0700_to_20200116_0800.csv')\n",
    "df_output_ATO_TDMS = df_output.drop(df_output[(df_output['ATO_0101__General'].isnull()) & (df_output['TDMS_002_General_Data'].isnull())].index)\n",
    "#drop column with prefix ATP and COM\n",
    "df_output_ATO_TDMS = df_output_ATO_TDMS.loc[:, ~df_output_ATO_TDMS.columns.str.startswith('ATP')]\n",
    "df_output_ATO_TDMS = df_output_ATO_TDMS.loc[:, ~df_output_ATO_TDMS.columns.str.startswith('COM')]\n",
    "df_output_ATO_TDMS['epoch'] = df_output_ATO_TDMS.epoch.values.astype(np.float64)\n",
    "df_output_ATO_TDMS = df_output_ATO_TDMS.reset_index(drop=True)\n",
    "print(df_output_ATO_TDMS.shape)\n",
    "#Output to CSV\n",
    "#df_output_ATO_TDMS.to_csv('./ATO_TDMS.csv', index=False, header=True)\n",
    "\n",
    "#df_drop = df_result_ATO_TDMS.drop(['Timestampms', 'TDMS_Date', 'TDMS_Timestamp', 'nearest_index'], axis=1)\n",
    "\n",
    "#Output to CSV\n",
    "df_result_ATO_TDMS.to_csv('./ATO_TDMS_Test.csv', index=False, header=True)\n",
    "df_drop_test = pd.read_csv('./ATO_TDMS_Test.csv')\n",
    "#df_drop_test = df_drop_test.sort_values(by='ATO_Real_Timestampms',ascending=True).reset_index(drop=True)\n",
    "# Assert whether sample output and self processed are equal\n",
    "assert_equal = nan_equal(df_drop_test['Real_Timestampms'].values, df_output_ATO_TDMS['epoch'].values)\n",
    "\n",
    "df_drop_test.columns = df_output_ATO_TDMS.columns\n",
    "print(np.testing.assert_allclose(df_drop_test.values, df_output_ATO_TDMS.values, rtol=1e-10, atol=0))\n",
    "print(pd.testing.assert_frame_equal(df_drop_test, df_output_ATO_TDMS, check_dtype=False))\n",
    "print(df_drop_test.compare(df_output_ATO_TDMS, align_axis=0))\n",
    "\n",
    "#assert_equal = nan_equal(df_drop_test.values, df_output_ATO_TDMS.values)\n",
    "#assert_equal = nan_equal(df_drop['ATO_* General'].values, df_output_ATO_TDMS['ATO_0101__General'].values)\n",
    "print(\"Equality Between Sample Output and Self Processed: \", assert_equal)\n",
    "#print(np.testing.assert_equal(df_drop_test.values, df_output_ATO_TDMS.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200116_05_00_00_333_OMAP_ATP.txt', '200116_06_00_00_333_OMAP_ATP.txt', '200116_07_00_00_333_OMAP_ATP.txt']\n",
      "Number of null value entry =  0\n"
     ]
    }
   ],
   "source": [
    "# Read files from ATP Directory\n",
    "path = './T20 OMAP DATA/Train 20 CSV/Car 39/200116/OMAP_ATP/'\n",
    "ATP_file_list = os.listdir(path)\n",
    "sorted(ATP_file_list)\n",
    "print(ATP_file_list)\n",
    "\n",
    "# Read & Clean the first ATP .txt\n",
    "df_ATP = pd.read_csv(path + ATP_file_list[index_file], sep=\"\\t\")\n",
    "df_ATP = clean_dataframe(df_ATP)\n",
    "\n",
    "# Preprocess Machine Time\n",
    "df_ATP = preprocess_machine_time(df_ATP)\n",
    "# Drop Timestamp Columns\n",
    "df_ATP.drop(['Date', 'Timestamp'], inplace=True, axis=1)\n",
    "\n",
    "# Add Prefix to Columns name (ATP_***)\n",
    "df_ATP = df_ATP.add_prefix('ATP_')\n",
    "# Rename ATP_Timestampms to the column Timestampms \n",
    "df_ATP.rename(columns = {\"ATP_Timestampms\": \"Timestampms\"},  inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 41089/41089 [00:09<00:00, 4543.02it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 41089/41089 [00:01<00:00, 28212.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 41089/41089 [00:24<00:00, 1674.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Merge ATP Dataframe to ATO Dataframe with same Timestampms\n",
    "df_result = pd.merge_ordered(df, df_ATP, how='outer', on='Timestampms')\n",
    "df_result['nearest_index'] = \"\"\n",
    "# Compute ATP real time and map it onto ATO while maintaining the ATP's time interval\n",
    "df_result[['Real_Timestampms', 'nearest_index']] = df_result.progress_apply(calculate_ATO_real_timestampms, axis=1)\n",
    "# Indicate which row needs to be switched\n",
    "df_result['nearest_index'] = df_result.progress_apply(indicate_switch, axis=1)\n",
    "# Switch row position \n",
    "df_result = df_result.progress_apply(switch_row_position, axis=1)\n",
    "# Drop nearest_index Column\n",
    "df_result.drop(['Timestampms', 'nearest_index'],inplace=True, axis=1)\n",
    "\n",
    "#print(df_result.columns)\n",
    "df_result_ATO_ATP = df_result.copy(deep=True)\n",
    "del df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41089, 546)\n",
      "None\n",
      "None\n",
      "             ATO_1220_Energy_delta  ATO_2008_ATP_Energy_delta\n",
      "26363 self                 223.434                    223.434\n",
      "      other                223.434                    223.434\n",
      "26364 self                 223.434                    223.434\n",
      "      other                223.434                    223.434\n",
      "26365 self                 223.434                    223.434\n",
      "...                            ...                        ...\n",
      "41077 other                677.366                    677.366\n",
      "41078 self                 677.366                    677.366\n",
      "      other                677.366                    677.366\n",
      "41080 self                 677.366                    677.366\n",
      "      other                677.366                    677.366\n",
      "\n",
      "[1550 rows x 2 columns]\n",
      "Equality Between Sample Output and Self Processed:  True\n"
     ]
    }
   ],
   "source": [
    "# Unit Test for ATO to ATP\n",
    "# Import Output File\n",
    "df_output = pd.read_csv(sample_output_filename)\n",
    "#df_output = pd.read_csv('./OMAP_Train_20_Car_39_20200116_0700_to_20200116_0800.csv')\n",
    "df_output_ATO_ATP = df_output.drop(df_output[(df_output['ATO_0101__General'].isnull()) & (df_output['ATP_002_Loc_fault'].isnull())].index)\n",
    "#drop column with prefix TDMS and COM\n",
    "df_output_ATO_ATP = df_output_ATO_ATP.loc[:, ~df_output_ATO_ATP.columns.str.startswith('TDMS')]\n",
    "df_output_ATO_ATP = df_output_ATO_ATP.loc[:, ~df_output_ATO_ATP.columns.str.startswith('COM')]\n",
    "df_output_ATO_ATP['epoch'] = df_output_ATO_ATP.epoch.values.astype(np.float64)\n",
    "df_output_ATO_ATP = df_output_ATO_ATP.reset_index(drop=True)\n",
    "print(df_output_ATO_ATP.shape)\n",
    "#Output to CSV\n",
    "#df_output_ATO_TDMS.to_csv('./ATO_TDMS.csv', index=False, header=True)\n",
    "\n",
    "#df_drop = df_result_ATO_ATP.drop(['Timestampms', 'TDMS_Date', 'TDMS_Timestamp', 'nearest_index'], axis=1)\n",
    "\n",
    "#Output to CSV\n",
    "df_result_ATO_ATP.to_csv('./ATO_ATP_Test.csv', index=False, header=True)\n",
    "df_drop_test = pd.read_csv('./ATO_ATP_Test.csv')\n",
    "df_drop_test = df_drop_test.sort_values(by='Real_Timestampms',ascending=True).reset_index(drop=True)\n",
    "# Assert whether sample output and self processed are equal\n",
    "assert_equal = nan_equal(df_drop_test['Real_Timestampms'].values, df_output_ATO_ATP['epoch'].values)\n",
    "\n",
    "df_drop_test.columns = df_output_ATO_ATP.columns\n",
    "print(np.testing.assert_allclose(df_drop_test.values, df_output_ATO_ATP.values, rtol=1e-10, atol=0))\n",
    "print(pd.testing.assert_frame_equal(df_drop_test, df_output_ATO_ATP, check_dtype=False))\n",
    "print(df_drop_test.compare(df_output_ATO_ATP, align_axis=0))\n",
    "\n",
    "#assert_equal = nan_equal(df_drop_test.values, df_output_ATO_TDMS.values)\n",
    "#assert_equal = nan_equal(df_drop['ATO_* General'].values, df_output_ATO_TDMS['ATO_0101__General'].values)\n",
    "print(\"Equality Between Sample Output and Self Processed: \", assert_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200116_05_00_00_333_OMAP_COM.txt', '200116_06_00_00_333_OMAP_COM.txt', '200116_07_00_00_333_OMAP_COM.txt']\n",
      "Number of null value entry =  0\n"
     ]
    }
   ],
   "source": [
    "# Read files from COM Directory\n",
    "path = './T20 OMAP DATA/Train 20 CSV/Car 39/200116/OMAP_COM/'\n",
    "COM_file_list = os.listdir(path)\n",
    "sorted(COM_file_list)\n",
    "print(COM_file_list)\n",
    "\n",
    "# Read & Clean the first ATP .txt\n",
    "df_COM = pd.read_csv(path + COM_file_list[index_file], sep=\"\\t\")\n",
    "df_COM = clean_dataframe(df_COM)\n",
    "\n",
    "# Preprocess Machine Time\n",
    "df_COM = preprocess_machine_time(df_COM)\n",
    "# Drop Date & Timestamp Columns\n",
    "df_COM.drop(['Date', 'Timestamp'], inplace=True, axis=1)\n",
    "\n",
    "# Add Prefix to Columns name (COM_***)\n",
    "df_COM = df_COM.add_prefix('COM_')\n",
    "# Rename COM_Timestampms to the column Timestampms \n",
    "df_COM.rename(columns = {\"COM_Timestampms\": \"Timestampms\"},  inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 41086/41086 [00:09<00:00, 4483.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 41086/41086 [00:01<00:00, 35433.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 41086/41086 [00:17<00:00, 2406.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Merge COM Dataframe to ATO Dataframe with same Timestampms\n",
    "df_result = pd.merge_ordered(df, df_COM, how='outer', on='Timestampms')\n",
    "df_result['nearest_index'] = \"\"\n",
    "# Compute ATP real time and map it onto ATO while maintaining the ATP's time interval\n",
    "df_result[['Real_Timestampms', 'nearest_index']] = df_result.progress_apply(calculate_ATO_real_timestampms, axis=1)\n",
    "# Indicate which row needs to be switched\n",
    "df_result['nearest_index'] = df_result.progress_apply(indicate_switch, axis=1)\n",
    "# Switch row position \n",
    "df_result = df_result.progress_apply(switch_row_position, axis=1)\n",
    "# Drop nearest_index Column\n",
    "df_result.drop(['Timestampms', 'nearest_index'],inplace=True, axis=1)\n",
    "df_result_ATO_COM = df_result.copy(deep=True)\n",
    "# del df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41086, 327)\n",
      "None\n",
      "None\n",
      "             ATO_1220_Energy_delta  ATO_2008_ATP_Energy_delta\n",
      "26327 self                 223.434                    223.434\n",
      "      other                223.434                    223.434\n",
      "26328 self                 223.434                    223.434\n",
      "      other                223.434                    223.434\n",
      "26329 self                 223.434                    223.434\n",
      "...                            ...                        ...\n",
      "41074 other                677.366                    677.366\n",
      "41075 self                 677.366                    677.366\n",
      "      other                677.366                    677.366\n",
      "41077 self                 677.366                    677.366\n",
      "      other                677.366                    677.366\n",
      "\n",
      "[1550 rows x 2 columns]\n",
      "Equality Between Sample Output and Self Processed:  True\n"
     ]
    }
   ],
   "source": [
    "# Unit Test for ATO to COM\n",
    "# Import Output File\n",
    "df_output = pd.read_csv(sample_output_filename)\n",
    "#df_output = pd.read_csv('./OMAP_Train_20_Car_39_20200116_0700_to_20200116_0800.csv')\n",
    "df_output_ATO_COM = df_output.drop(df_output[(df_output['ATO_0101__General'].isnull()) & (df_output['COM_002_SAFE_INPUTS'].isnull())].index)\n",
    "#drop column with prefix TDMS and COM\n",
    "df_output_ATO_COM = df_output_ATO_COM.loc[:, ~df_output_ATO_COM.columns.str.startswith('TDMS')]\n",
    "df_output_ATO_COM = df_output_ATO_COM.loc[:, ~df_output_ATO_COM.columns.str.startswith('ATP')]\n",
    "df_output_ATO_COM['epoch'] = df_output_ATO_COM.epoch.values.astype(np.float64)\n",
    "df_output_ATO_COM = df_output_ATO_COM.reset_index(drop=True)\n",
    "print(df_output_ATO_COM.shape)\n",
    "#Output to CSV\n",
    "#df_output_ATO_TDMS.to_csv('./ATO_TDMS.csv', index=False, header=True)\n",
    "\n",
    "#df_drop = df_result_ATO_ATP.drop(['Timestampms', 'TDMS_Date', 'TDMS_Timestamp', 'nearest_index'], axis=1)\n",
    "\n",
    "#Output to CSV\n",
    "df_result_ATO_COM.to_csv('./ATO_COM_Test.csv', index=False, header=True)\n",
    "df_drop_test = pd.read_csv('./ATO_COM_Test.csv')\n",
    "df_drop_test = df_drop_test.sort_values(by='Real_Timestampms',ascending=True).reset_index(drop=True)\n",
    "# Assert whether sample output and self processed are equal\n",
    "assert_equal = nan_equal(df_drop_test['Real_Timestampms'].values, df_output_ATO_COM['epoch'].values)\n",
    "\n",
    "df_drop_test.columns = df_output_ATO_COM.columns\n",
    "print(np.testing.assert_allclose(df_drop_test.values, df_output_ATO_COM.values, rtol=1e-10, atol=0))\n",
    "print(pd.testing.assert_frame_equal(df_drop_test, df_output_ATO_COM, check_dtype=False))\n",
    "print(df_drop_test.compare(df_output_ATO_COM, align_axis=0))\n",
    "\n",
    "#assert_equal = nan_equal(df_drop_test.values, df_output_ATO_TDMS.values)\n",
    "#assert_equal = nan_equal(df_drop['ATO_* General'].values, df_output_ATO_TDMS['ATO_0101__General'].values)\n",
    "print(\"Equality Between Sample Output and Self Processed: \", assert_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41089, 546) (41086, 48)\n"
     ]
    }
   ],
   "source": [
    "# Merge Result ATO_ATP and ATO_COM based on Real Timestampms\n",
    "# First drop ATO columns from ATO_COM\n",
    "df_result_drop_ATO_COM = df_result_ATO_COM.loc[:, ~df_result_ATO_COM.columns.str.startswith('ATO')]\n",
    "# duplicateRowsDF = df_result_drop_ATO_COM[df_result_drop_ATO_COM.duplicated()]\n",
    "# print(duplicateRowsDF)\n",
    "\n",
    "#df_result_drop_ATO_COM.info(verbose=True)\n",
    "#df_result_ATO_ATP.info(verbose=True)\n",
    "print(df_result_ATO_ATP.shape, df_result_drop_ATO_COM.shape)\n",
    "# Merge onto result ATO_ATP\n",
    "df_temp_result = pd.merge_ordered(df_result_ATO_ATP, df_result_drop_ATO_COM, how='outer', on='Real_Timestampms')\n",
    "\n",
    "# First drop ATO columns from ATO_COM\n",
    "df_result_drop_ATO_TDMS = df_result_ATO_TDMS.loc[:, ~df_result_ATO_TDMS.columns.str.startswith('ATO')]\n",
    "# Merge TDMS onto the result dataframe\n",
    "df_temp_result = pd.merge_ordered(df_temp_result, df_result_drop_ATO_TDMS, how='outer', on='Real_Timestampms')\n",
    "\n",
    "df_temp_result.to_csv('./temp_result.csv', index=False, header=True)\n",
    "print(\"Time Taken:\", timeit.default_timer() - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50886, 751)\n",
      "Equality Between Sample Output and Self Processed:  True\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATO_1220_Energy_delta</th>\n",
       "      <th>ATO_2008_ATP_Energy_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32927</th>\n",
       "      <th>self</th>\n",
       "      <td>223.434</td>\n",
       "      <td>223.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>223.434</td>\n",
       "      <td>223.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32928</th>\n",
       "      <th>self</th>\n",
       "      <td>223.434</td>\n",
       "      <td>223.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>223.434</td>\n",
       "      <td>223.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32929</th>\n",
       "      <th>self</th>\n",
       "      <td>223.434</td>\n",
       "      <td>223.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50874</th>\n",
       "      <th>other</th>\n",
       "      <td>677.366</td>\n",
       "      <td>677.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">50875</th>\n",
       "      <th>self</th>\n",
       "      <td>677.366</td>\n",
       "      <td>677.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>677.366</td>\n",
       "      <td>677.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">50877</th>\n",
       "      <th>self</th>\n",
       "      <td>677.366</td>\n",
       "      <td>677.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>677.366</td>\n",
       "      <td>677.366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1550 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ATO_1220_Energy_delta  ATO_2008_ATP_Energy_delta\n",
       "32927 self                 223.434                    223.434\n",
       "      other                223.434                    223.434\n",
       "32928 self                 223.434                    223.434\n",
       "      other                223.434                    223.434\n",
       "32929 self                 223.434                    223.434\n",
       "...                            ...                        ...\n",
       "50874 other                677.366                    677.366\n",
       "50875 self                 677.366                    677.366\n",
       "      other                677.366                    677.366\n",
       "50877 self                 677.366                    677.366\n",
       "      other                677.366                    677.366\n",
       "\n",
       "[1550 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test for End Result\n",
    "# Import Output File\n",
    "df_output = pd.read_csv(sample_output_filename)\n",
    "#df_output = pd.read_csv('./OMAP_Train_20_Car_39_20200116_0700_to_20200116_0800.csv')\n",
    "#df_output['epoch'] = df_output.epoch.values.astype(np.float64)\n",
    "#df_output = df_output.reset_index(drop=True)\n",
    "print(df_output.shape)\n",
    "#assert_equal = nan_equal(df_temp_result['Real_Timestampms'].values, df_output['epoch'].values)\n",
    "#assert_equal = nan_equal(df_drop_test.values, df_output_ATO_TDMS.values)\n",
    "assert_equal = nan_equal(df_temp_result['ATO_* General'].values, df_output['ATO_0101__General'].values)\n",
    "print(\"Equality Between Sample Output and Self Processed: \", assert_equal)\n",
    "#print(np.testing.assert_equal(df_temp_result.values, df_output.values))\n",
    "print(np.testing.assert_equal(df_temp_result['Real_Timestampms'].values, df_output['epoch'].values))\n",
    "print(np.testing.assert_equal(df_temp_result['ATO_* General'].values, df_output['ATO_0101__General'].values))\n",
    "print(np.testing.assert_equal(df_temp_result['ATP_Loc fault'].values, df_output['ATP_002_Loc_fault'].values))\n",
    "print(np.testing.assert_equal(df_temp_result['COM_SAFE INPUTS'].values, df_output['COM_002_SAFE_INPUTS'].values))\n",
    "print(np.testing.assert_equal(df_temp_result['TDMS_General Data'].values, df_output['TDMS_002_General_Data'].values))\n",
    "print(np.testing.assert_equal(df_temp_result['TDMS_Sec'].values, df_output['TDMS_016_Sec'].values))\n",
    "\n",
    "# Energry Delta has some error (show in powerpoint slides).\n",
    "#print(np.testing.assert_equal(df_temp_result['ATO_Energy delta'].values, df_output['ATO_1220_Energy_delta'].values))\n",
    "\n",
    "#print(np.testing.assert_allclose(df_temp_result.values, df_output.values, rtol=1e-10, atol=0))\n",
    "#print(np.testing.assert_equal(df_temp_result.values, df_output.values))\n",
    "df_temp_result_2 = df_temp_result.copy(deep=True)\n",
    "df_temp_result_2.columns = df_output.columns\n",
    "print(pd.testing.assert_frame_equal(df_temp_result_2, df_output, check_dtype=False, check_column_type=False))\n",
    "df_temp_result_2.compare(df_output, align_axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unit Test for ATP & COM\n",
    "# # Import Output File\n",
    "# df_output = pd.read_csv('./OMAP_Train_20_Car_39_20200116_0600_to_20200116_0700.csv')\n",
    "\n",
    "# df_output_ATP_COM = df_output.drop(df_output[(df_output['ATP_002_Loc_fault'].isnull()) & (df_output['COM_002_SAFE_INPUTS'].isnull())].index)\n",
    "# # Drop column with prefix ATO and TDMS\n",
    "# df_output_ATP_COM = df_output_ATP_COM.loc[:, ~df_output_ATP_COM.columns.str.startswith('ATO')]\n",
    "# df_output_ATP_COM = df_output_ATP_COM.loc[:, ~df_output_ATP_COM.columns.str.startswith('TDMS')]\n",
    "# df_output_ATP_COM = df_output_ATP_COM.reset_index(drop=True)\n",
    "# # Drop epoch as we're not comparing the timestamp\n",
    "# df_output_ATP_COM = df_output_ATP_COM.drop(['epoch'], axis=1)\n",
    "# df_output_ATP_COM = df_output_ATP_COM.reset_index(drop=True)\n",
    "# print(df_output_ATP_COM.shape)\n",
    "\n",
    "\n",
    "# df_result_ATP_COM_test = pd.read_csv('./ATP_COM_Test.csv')\n",
    "# #df_result_ATP_COM_test = df_result_ATP_COM_test.drop(['Timestampms'], axis=1)\n",
    "# print(df_result_ATP_COM_test.shape)\n",
    "\n",
    "\n",
    "# df_result_ATP_COM_test['result_3'] = df_result_ATP_COM_test['ATP_Invariants Elapsed'].fillna('-').eq(df_output_ATP_COM['ATP_043_Invariants_Elapsed'].fillna('-'))\n",
    "# print(df_result_ATP_COM_test['result_3'].value_counts())\n",
    "# df_result_ATP_COM_test.to_csv('./ATP_COM_Test_1.csv', index=False, header=True)\n",
    "\n",
    "\n",
    "# assert_equal = nan_equal(df_result_ATP_COM_test['ATP_Invariants Elapsed'].values, df_output_ATP_COM['ATP_043_Invariants_Elapsed'].values)\n",
    "# print(\"Equality Between Sample Output and Self Processed: \", assert_equal)\n",
    "# #print(np.testing.assert_equal(df_result_ATP_COM_test['ATP_Invariants Elapsed'].values, df_output_ATP_COM['ATP_043_Invariants_Elapsed'].values))\n",
    "\n",
    "# # ***** Cant do a unit test here as the swap of real time hasnt occurred.\n",
    "\n",
    "# # df_result_ATP_COM_test.to_csv('./ATP_COM_Test_1.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_for_monotonic (df):\n",
    "#     \"\"\" Return a dataframe\n",
    "    \n",
    "#     Detect and clean unsequence real time\n",
    "    \n",
    "#     Edge cases might not be covered(e.g. 10 10 10 11 11 11 10 10 10, 11 11 11 10 10 10 11 11 11)\n",
    "#     \"\"\"\n",
    "#     if not df['Realtime'].is_monotonic_increasing:\n",
    "#         # Get index of non-monotonic location - non increasing order\n",
    "#         df_non_monotonic = df.loc[df['Realtime'].diff() < pd.to_timedelta('0 seconds')]\n",
    "        \n",
    "#         # *** Need to determine if for loop forward or backwards (changing to which real time index) - Not Implemented\n",
    "        \n",
    "#         print(\"Found non-monotonic sequence at index: \", (df.loc[df['Realtime'].diff() < pd.to_timedelta('0 seconds')].index))\n",
    "#         for index in df_non_monotonic.index:\n",
    "#             non_monotonic_realtime = df['Realtime'][index-1]\n",
    "#             counter = 0\n",
    "#             # Loop backwards to find how many non_monotonic_realtime count \n",
    "#             while(True and (index-1-counter >0)):\n",
    "#                 if non_monotonic_realtime == df['Realtime'][index-1-counter]:\n",
    "#                     counter += 1\n",
    "#                 else:\n",
    "#                     break\n",
    "#             #print(counter)\n",
    "            \n",
    "#             # Find start location of index with the same real time (index)\n",
    "#             start_index = min(df[df['Realtime'] == df['Realtime'][index]].index)\n",
    "#             total_no_interval = len(df[df['Realtime'] == df['Realtime'][index]].index) - counter\n",
    "            \n",
    "#             # Next time index information\n",
    "#             start_index_next_realtime = start_index + total_no_interval\n",
    "#             total_no_interval_next_realtime = len(df[df['Realtime'] == df['Realtime'][index-1]]) + counter\n",
    "#             next_realtime = df['Realtime'][index-1]\n",
    "            \n",
    "#             # Update Real Time\n",
    "#             for count in range (0,counter):\n",
    "#                 df.loc[index-1-count,'Realtime'] = df['Realtime'][index]\n",
    "#                 #print(index-1-count, df.loc[index-1-count,'Realtime'])\n",
    "                                \n",
    "#             # Update Real time for the next time index\n",
    "#             for count in range (0,total_no_interval_next_realtime):\n",
    "#                 df.loc[start_index_next_realtime+count,'Realtime'] = next_realtime\n",
    "#                 #print(start_index_next_realtime+count, df.loc[start_index_next_realtime+count,'Realtime'])\n",
    "#     return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
